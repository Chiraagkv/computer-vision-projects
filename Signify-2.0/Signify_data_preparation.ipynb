{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Signify-data-preparation.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_cUtzeyq9qbp",
        "Fu5GhiNO-RVH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_cUtzeyq9qbp"
      },
      "source": [
        "# **0. Setup** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SByZJLdT9iRs",
        "outputId": "d76dbe11-8b7a-4e37-a216-f8583fc92204"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "!pip install mediapipe\n",
        "import mediapipe as mp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mediapipe\n",
            "  Downloading mediapipe-0.8.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 52 kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.37.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (21.2.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.11.0)\n",
            "Installing collected packages: mediapipe\n",
            "Successfully installed mediapipe-0.8.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rvyyp5FC9vFn",
        "outputId": "d5ce7578-693c-4834-90ad-deaf188dbc84"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/MyDrive/Colab Notebooks/ASL/data/MP4.zip\"\n",
        "with ZipFile(file_name, 'r') as zipp:\n",
        "    print('Extracting all the files now...')\n",
        "    zipp.extractall()\n",
        "    print('Done!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting all the files now...\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fu5GhiNO-RVH"
      },
      "source": [
        "# **1. Data Pre-processing**\n",
        "\n",
        "* **Extract Frames**\n",
        "* **Extract and pre-process the keypoint locations**\n",
        "* **Pad the keypoints**\n",
        "* **Pre-process labels**\n",
        "* **Do all of the above for 1 video**\n",
        "* **Do all of the above for all videos**\n",
        "* **Fix the keypoint padding**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEm8nqZOJFE0"
      },
      "source": [
        "## **Extract Frames**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJLxmg0w-jBQ"
      },
      "source": [
        "def extract_frames(video_path):\n",
        "    '''A function that extracts all frames of a video, appends it to a list and return the list.\n",
        "    \n",
        "    Args:\n",
        "        video_path: The path of the video.\n",
        "    '''\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if ret:\n",
        "          frames.append(frame)\n",
        "        else:\n",
        "            break\n",
        "    return frames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-EKmLX1-mPe"
      },
      "source": [
        "def remove_empty_frames(frames):\n",
        "  '''A function that removes empty frames from a video\n",
        "    \n",
        "    Args:\n",
        "        frames: a list of video frames\n",
        "  '''\n",
        "  unempty_frames = []\n",
        "\n",
        "  for frame in frames:\n",
        "    unique_values = np.unique(frame)\n",
        "    if len(unique_values) == 1 and unique_values[0] == 0:\n",
        "      continue\n",
        "    else:\n",
        "      unempty_frames.append(frame)\n",
        "  \n",
        "  return unempty_frames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXNUsYGLJJCY"
      },
      "source": [
        "## **Extract and Pre-process keypoint locations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPNT_Z3ngqad"
      },
      "source": [
        "def zip_three_lists(x, y, z):\n",
        "  zipped = []\n",
        "  for i in range(len(x)):\n",
        "    zip_list = x[i], y[i], z[i]\n",
        "    zipped.append(zip_list)\n",
        "  return np.array(zipped)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54WzLbd2gu2p"
      },
      "source": [
        "def clean_keypoints(keypoints, precision=5):\n",
        "  str_keypoints = str(keypoints)\n",
        "  x = []\n",
        "  y = []\n",
        "  z = []\n",
        "  for i in range(len(str_keypoints)):\n",
        "    if str_keypoints[i] == \"x\" and str_keypoints[i-1] == \" \":\n",
        "      x.append(float(str_keypoints[i + 3: i + 8]))\n",
        "    elif str_keypoints[i] == \"y\" and str_keypoints[i-1] == \" \":\n",
        "      y.append(float(str_keypoints[i + 3: i + 8]))\n",
        "    elif str_keypoints[i] == \"z\" and str_keypoints[i-1] == \" \":\n",
        "      z.append(float(str_keypoints[i + 3: i + 8]))\n",
        "  \n",
        "  # coordinates = zip_three_lists(x, y, z)\n",
        "  # return coordinates\n",
        "  return zip_three_lists(x, y, z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibK7oLH4-pmk"
      },
      "source": [
        "def extract_pose(frame, output_shape=(224, 224, 3), output=\"list\"):\n",
        "  '''A function that extracts and draws the keypoints using `mediapipe.solutions.pose.Pose()`\n",
        "    \n",
        "    Args:\n",
        "        video_path: The path of the video.\n",
        "        output_shape: the shape of the output images\n",
        "    '''\n",
        "  location = []\n",
        "  try:\n",
        "    mp_drawing = mp.solutions.drawing_utils\n",
        "    mp_drawing_styles = mp.solutions.drawing_styles\n",
        "    mp_pose = mp.solutions.pose\n",
        "    video_frames = []\n",
        "    with mp_pose.Pose(static_image_mode=True, model_complexity=2, min_detection_confidence=0.5) as pose:\n",
        "      image = cv2.resize(frame, (output_shape[0], output_shape[1]))\n",
        "      image_height, image_width, _ = image.shape\n",
        "      one_image = []\n",
        "      # Convert the BGR image to RGB before processing.\n",
        "      results = pose.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "      location = clean_keypoints(results.pose_landmarks)\n",
        "      if output != \"list\":\n",
        "        return location\n",
        "      else:\n",
        "        return list(location)\n",
        "  except Exception as e:\n",
        "    return np.zeros((33, 3))\n",
        "\n",
        "# Trial\n",
        "# location1 = extract_pose(extract_frames(\"/content/MP4/(ON_THE)LEFT 01.mp4\")[5], output=\"array\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmhyAEVWJR2j"
      },
      "source": [
        "## **Pad the keypoints**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_k6SuglwAwSV"
      },
      "source": [
        "def pad_coordinates(coordinates, maxlen=80):\n",
        "  frames = coordinates.shape[0]\n",
        "  keypoints, coor = 33, 3\n",
        "  difference = maxlen - frames\n",
        "  start = end = difference / 2\n",
        "  if isinstance(start, float):\n",
        "    start -= 0.5\n",
        "    end += 0.5\n",
        "  if start != 0:\n",
        "    pad_values_start = list(tf.ones((int(start), keypoints, coor)) - 3)\n",
        "    pad_values_end = list(tf.ones((int(end), keypoints, coor)) - 3)\n",
        "    output = pad_values_start + list(coordinates) + pad_values_end\n",
        "  else:\n",
        "    pad_values_end = list(tf.zeros(int(end), keypoints, coor) - 3)\n",
        "    output = list(coordinates) + pad_values_end\n",
        "  return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPl9whDN5c4h"
      },
      "source": [
        "## **Preprocess labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6W431gTyOuI"
      },
      "source": [
        " labels = np.unique(sorted([i.split(\"0\")[0].strip() for i in os.listdir(\"/content/MP4\")]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhIsTgnsyVj3"
      },
      "source": [
        "def preprocess_label(label):\n",
        "  '''A function that pre-processes a label\n",
        "    \n",
        "    Args:\n",
        "        label: a single string. the label to a video\n",
        "  '''\n",
        "  return label.split(\"01\")[0].split(\"4/\")[1].strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yaYC6gSyWcj",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "# def encode_labels(label, video_length, labels_array=labels):\n",
        "#   '''A function that converts a label to an array of numbers, that is appended to another array for `video_length` number of times\n",
        "    \n",
        "#     Args:\n",
        "#         label: a single string. the label to a video\n",
        "#         video_length: the length of the video to which the label corresponds to\n",
        "#         labels_array: an array of all labels \n",
        "#   '''\n",
        "\n",
        "#   labels_binary = []\n",
        "#   bool_array = preprocess_label(label) == labels_array\n",
        "#   numerical_labels = list(bool_array.astype(int))\n",
        "#   for i in range(video_length):\n",
        "#     labels_binary.append(numerical_labels)\n",
        "#   return np.array(labels_binary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twy9CSYm8Arr"
      },
      "source": [
        "def get_labels(label):\n",
        "  bool_array = preprocess_label(label) == labels\n",
        "  numerical_labels = list(bool_array.astype(int))\n",
        "  return numerical_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWj0qpVE5h0u"
      },
      "source": [
        "## **Do all of the above for 1 video**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPAhsrQQtYBy"
      },
      "source": [
        "videos = [\"/content/MP4/\" + i for i in os.listdir(\"/content/MP4\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbKerxQUxDXZ"
      },
      "source": [
        "def preprocess_single_video(video_path):\n",
        "  frames = extract_frames(video_path)\n",
        "  coordinates = []\n",
        "  for frame in frames:\n",
        "    coors = extract_pose(frame)\n",
        "    if np.array(coors).shape == (0, ):\n",
        "      coors = list(np.zeros((33, 3)))      \n",
        "    coordinates.append(coors)\n",
        "  x = pad_coordinates(np.array(coordinates))\n",
        "  y = list(get_labels(video_path))\n",
        "  return x, y\n",
        "\n",
        "# Trial\n",
        "# X, Y = preprocess_single_video(videos[9])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knKN8VnfJjPr"
      },
      "source": [
        "## **Do all of the above for all videos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXyqOlBjzay6",
        "outputId": "c351ccb1-3628-4016-acad-e8d5c3d43733"
      },
      "source": [
        "def preprocess_videos(video_paths):\n",
        "  X = []\n",
        "  Y = []\n",
        "  i = 1\n",
        "  for video in video_paths:\n",
        "    x, y = preprocess_single_video(video)\n",
        "    X.append(x)\n",
        "    Y.append(y)\n",
        "    print(i)\n",
        "    i += 1\n",
        "  \n",
        "  return X, Y\n",
        "\n",
        "X, Y = preprocess_videos(videos[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading model to /usr/local/lib/python3.7/dist-packages/mediapipe/modules/pose_landmark/pose_landmark_heavy.tflite\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3G81r_g6JoF0"
      },
      "source": [
        "## **Fix the keypoint padding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAKtWvFi0Tx0"
      },
      "source": [
        "def standardize_shapes(ragged_X):\n",
        "  correctedX = []\n",
        "  for i in ragged_X:\n",
        "    if np.array(i).shape == (80, 33, 3):\n",
        "      a = list(i)\n",
        "      a.pop(-1)\n",
        "      correctedX.append(a)\n",
        "    else:\n",
        "      correctedX.append(i)\n",
        "  return np.array(correctedX)\n",
        "\n",
        "X = standardize_shapes(X)\n",
        "y = np.array(Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwn2A3PX5rYt",
        "outputId": "08df9310-952a-48e8-8893-cb2e3acd746d"
      },
      "source": [
        "X.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5, 79, 33, 3), (5, 42))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}